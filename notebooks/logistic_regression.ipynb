{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LinearRegressionClient(torch.nn.Module):\n",
    "    def __init__(self, in_layer, out_layer, learn_rate, criterion, optimizer):\n",
    "        super(LinearRegressionClient, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_layer, out_layer, bias=True)\n",
    "        self.criterion = criterion\n",
    "        self.optimizer = optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "    def train_model(self, epochs: int, x_data, y_data):\n",
    "        for epoch in range(epochs):\n",
    "            model = self.linear\n",
    "            model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            y_pred = model(x_data)\n",
    "            # Compute Loss\n",
    "            loss = self.criterion(y_pred, y_data)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        print(\"Loss: \"+ str(loss.data.view(-1)))\n",
    "\n",
    "    \n",
    "    def set_parameters_as_tensor(self, weights: torch.Tensor):\n",
    "        if not isinstance(weights, torch.Tensor):\n",
    "            print(\"Converting weights to tensor type\")\n",
    "            weights = torch.tensor(weights)\n",
    "        current_index = 0 \n",
    "        for parameter in self.parameters():\n",
    "            numel = parameter.data.numel()\n",
    "            size = parameter.data.size()\n",
    "            parameter.data.copy_(\n",
    "                            weights[current_index:current_index +\n",
    "                                                numel].view(size))\n",
    "            current_index+=1\n",
    "\n",
    "    def get_parameters_as_tensor(self):\n",
    "        params = [param.data.view(-1) for param in self.parameters()]\n",
    "        params = torch.cat(params)\n",
    "        params = params.cpu()\n",
    "        return params\n",
    "\n",
    "    def run(in_layer, out_layer, learn_rate=0.1, criterion=None, optimizer=None):\n",
    "        criterion = torch.nn.MSELoss(size_average=False)\n",
    "        optimizer = torch.optim.SGD(self.linear.parameters(), lr=learn_rate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionFederated:\n",
    "    def __init__(self, models: LinearRegressionClient, data_federation):\n",
    "        self.models = models\n",
    "        self.data_federation = data_federation\n",
    "    \n",
    "    def get_average_model(self):\n",
    "\n",
    "        #Pull parameters for each model locally\n",
    "        model_parameters = []\n",
    "        for model in self.models:\n",
    "            model_parameters.append(model.get_parameters_as_tensor())\n",
    "        \n",
    "        #TODO: Push list of model parameters to some SCN\n",
    "        for param in model_parameters:\n",
    "            break\n",
    "            # param.send(models[random])\n",
    "\n",
    "        #Calculate the Mean Remotely\n",
    "        #TODO: DO this using existing safe object\n",
    "        model_sum = 0.\n",
    "        for param in model_parameters:\n",
    "            model_sum += param\n",
    "        model_avg = model_sum/len(self.models)\n",
    "        #TODO: Pull result to orchestrator\n",
    "\n",
    "        return model_avg\n",
    "    \n",
    "    def train_cycle(self, epochs: int):\n",
    "        #train individual models on data\n",
    "        for i in range(len(self.models)):\n",
    "            models[i].train_model(epochs, data_federation[i][0], data_federation[i][1])\n",
    "        \n",
    "        #average the models\n",
    "        avg_model = self.get_average_model()\n",
    "        for i in range(len(self.models)):\n",
    "            models[i].set_parameters_as_tensor(avg_model)\n",
    "\n",
    "        #TODO:Pull Result locally           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 3 required positional arguments: 'learn_rate', 'criterion', and 'optimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/AdamHall/Documents/GitHub/datascience/notebooks/logistic_regression.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/mnt/c/Users/AdamHall/Documents/GitHub/datascience/notebooks/logistic_regression.ipynb#ch0000002vscode-remote?line=4'>5</a>\u001b[0m y_dataB \u001b[39m=\u001b[39m Variable(torch\u001b[39m.\u001b[39mTensor([[\u001b[39m60.0\u001b[39m], [\u001b[39m70.0\u001b[39m], [\u001b[39m40.0\u001b[39m], [\u001b[39m20.0\u001b[39m]]))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/mnt/c/Users/AdamHall/Documents/GitHub/datascience/notebooks/logistic_regression.ipynb#ch0000002vscode-remote?line=5'>6</a>\u001b[0m data_federation \u001b[39m=\u001b[39m [[x_dataA, y_dataA], [x_dataB, y_dataB]]\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/mnt/c/Users/AdamHall/Documents/GitHub/datascience/notebooks/logistic_regression.ipynb#ch0000002vscode-remote?line=7'>8</a>\u001b[0m modelA \u001b[39m=\u001b[39m LinearRegressionClient(\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/mnt/c/Users/AdamHall/Documents/GitHub/datascience/notebooks/logistic_regression.ipynb#ch0000002vscode-remote?line=8'>9</a>\u001b[0m modelB \u001b[39m=\u001b[39m LinearRegressionClient(\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu20.04lts/mnt/c/Users/AdamHall/Documents/GitHub/datascience/notebooks/logistic_regression.ipynb#ch0000002vscode-remote?line=9'>10</a>\u001b[0m models \u001b[39m=\u001b[39m [modelA, modelB]\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 3 required positional arguments: 'learn_rate', 'criterion', and 'optimizer'"
     ]
    }
   ],
   "source": [
    "#Data Starts with respective owners A and B\n",
    "x_dataA = Variable(torch.Tensor([[10.0], [9.0], [3.0], [2.0]]))\n",
    "y_dataA = Variable(torch.Tensor([[90.0], [80.0], [50.0], [30.0]]))\n",
    "x_dataB = Variable(torch.Tensor([[7.0], [8.0], [3.0], [1.0]]))\n",
    "y_dataB = Variable(torch.Tensor([[60.0], [70.0], [40.0], [20.0]]))\n",
    "data_federation = [[x_dataA, y_dataA], [x_dataB, y_dataB]]\n",
    "        \n",
    "modelA = LinearRegressionClient(1,1)\n",
    "modelB = LinearRegressionClient(1,1)\n",
    "models = [modelA, modelB]\n",
    "\n",
    "federated_model = LinearRegressionFederated(models, data_federation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor([1.3727e+34])\n",
      "Loss: tensor([8.7761e+33])\n",
      "Loss: tensor([1.3438e+37])\n",
      "Loss: tensor([8.5908e+36])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n",
      "Loss: tensor([inf])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # print(federated_model.models[0].get_parameters_as_tensor())\n",
    "    # print(federated_model.models[1].get_parameters_as_tensor())\n",
    "    federated_model.train_cycle(1)\n",
    "    # print(federated_model.models[0].get_parameters_as_tensor())\n",
    "    # print(federated_model.models[1].get_parameters_as_tensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a551a9fda4b0fd0844678eafd3b71ce0ebfefa198dcee60abe1926ee3f4a81d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv38_sail': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
