{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "def get_kidney_dataframe():\n",
    "\n",
    "    DATA_PATH = \"../../sail-safe-functions-test/sail_safe_functions_test/data_sail_safe_functions\"\n",
    "    path_file_csv = os.path.join(DATA_PATH, \"data_csv_kidney_clean\", \"kidney_disease_clean.csv\")\n",
    "    df =  pd.read_csv(path_file_csv)\n",
    "    df = pd.get_dummies(data=df)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_test_federation_split(df):\n",
    "\n",
    "    train = df.sample(frac=0.8, random_state=0)\n",
    "    test = df.drop(train.index)\n",
    "    \n",
    "    shuffled = train.sample(frac=1)\n",
    "    result = np.array_split(shuffled, 5)  \n",
    "\n",
    "    return result, test\n",
    "\n",
    "dataframe = get_kidney_dataframe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data_federation = dataframe\n",
    "\n",
    "X_col = ['age']\n",
    "Y_col = ['age']\n",
    "in_layer = len(X_col)\n",
    "out_layer = len(Y_col)\n",
    "optimizer = \"SGD\"\n",
    "criterion = \"MSELoss\"\n",
    "epochs = 1000\n",
    "learn_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'age', 'bp', 'sg', 'al', 'su', 'bgr', 'bu', 'sc', 'sod', 'pot',\n",
       "       'hemo', 'pcv', 'wc', 'rc', 'rbc_abnormal', 'rbc_normal', 'pc_abnormal',\n",
       "       'pc_normal', 'pcc_notpresent', 'pcc_present', 'ba_notpresent',\n",
       "       'ba_present', 'htn_no', 'htn_yes', 'dm_ yes', 'dm_no', 'dm_yes',\n",
       "       'cad_no', 'cad_yes', 'appet_good', 'appet_poor', 'pe_no', 'pe_yes',\n",
       "       'ane_no', 'ane_yes', 'classification_ckd', 'classification_notckd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_libs.shared.models.LinearRegression import LinearRegression\n",
    "\n",
    "model = LinearRegression(in_layer, out_layer)\n",
    "\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)\n",
    "\n",
    "inputs = Variable(ModelUtility.dataframe_to_tensor(dataframe[X_col]))\n",
    "labels = Variable(ModelUtility.dataframe_to_tensor(dataframe[Y_col]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(691.0760, grad_fn=<MseLossBackward0>)\n",
      "epoch 0, loss 691.0759887695312\n",
      "tensor(117.1776, grad_fn=<MseLossBackward0>)\n",
      "epoch 1, loss 117.17761993408203\n",
      "tensor(19.8684, grad_fn=<MseLossBackward0>)\n",
      "epoch 2, loss 19.868431091308594\n",
      "tensor(3.3689, grad_fn=<MseLossBackward0>)\n",
      "epoch 3, loss 3.3688526153564453\n",
      "tensor(0.5712, grad_fn=<MseLossBackward0>)\n",
      "epoch 4, loss 0.5712161064147949\n",
      "tensor(0.0969, grad_fn=<MseLossBackward0>)\n",
      "epoch 5, loss 0.09685426950454712\n",
      "tensor(0.0164, grad_fn=<MseLossBackward0>)\n",
      "epoch 6, loss 0.01642214134335518\n",
      "tensor(0.0028, grad_fn=<MseLossBackward0>)\n",
      "epoch 7, loss 0.0027844009455293417\n",
      "tensor(0.0005, grad_fn=<MseLossBackward0>)\n",
      "epoch 8, loss 0.0004721646837424487\n",
      "tensor(8.0062e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch 9, loss 8.006174175534397e-05\n",
      "tensor(1.3580e-05, grad_fn=<MseLossBackward0>)\n",
      "epoch 10, loss 1.3580201084550936e-05\n",
      "tensor(2.2968e-06, grad_fn=<MseLossBackward0>)\n",
      "epoch 11, loss 2.296835418746923e-06\n",
      "tensor(3.9027e-07, grad_fn=<MseLossBackward0>)\n",
      "epoch 12, loss 3.9027253251333605e-07\n",
      "tensor(6.5189e-08, grad_fn=<MseLossBackward0>)\n",
      "epoch 13, loss 6.518891382256697e-08\n",
      "tensor(1.1411e-08, grad_fn=<MseLossBackward0>)\n",
      "epoch 14, loss 1.1410606681749869e-08\n",
      "tensor(2.0400e-09, grad_fn=<MseLossBackward0>)\n",
      "epoch 15, loss 2.0399604228060753e-09\n",
      "tensor(3.6789e-10, grad_fn=<MseLossBackward0>)\n",
      "epoch 16, loss 3.678861937306266e-10\n",
      "tensor(1.1573e-10, grad_fn=<MseLossBackward0>)\n",
      "epoch 17, loss 1.1573309671719656e-10\n",
      "tensor(2.3647e-11, grad_fn=<MseLossBackward0>)\n",
      "epoch 18, loss 2.364661418063907e-11\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 19, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 20, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 21, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 22, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 23, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 24, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 25, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 26, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 27, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 28, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 29, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 30, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 31, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 32, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 33, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 34, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 35, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 36, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 37, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 38, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 39, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 40, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 41, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 42, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 43, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 44, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 45, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 46, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 47, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 48, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 49, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 50, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 51, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 52, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 53, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 54, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 55, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 56, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 57, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 58, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 59, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 60, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 61, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 62, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 63, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 64, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 65, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 66, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 67, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 68, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 69, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 70, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 71, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 72, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 73, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 74, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 75, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 76, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 77, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 78, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 79, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 80, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 81, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 82, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 83, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 84, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 85, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 86, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 87, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 88, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 89, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 90, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 91, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 92, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 93, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 94, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 95, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 96, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 97, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 98, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 99, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 100, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 101, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 102, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 103, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 104, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 105, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 106, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 107, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 108, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 109, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 110, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 111, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 112, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 113, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 114, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 115, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 116, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 117, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 118, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 119, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 120, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 121, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 122, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 123, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 124, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 125, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 126, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 127, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 128, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 129, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 130, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 131, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 132, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 133, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 134, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 135, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 136, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 137, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 138, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 139, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 140, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 141, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 142, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 143, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 144, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 145, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 146, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 147, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 148, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 149, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 150, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 151, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 152, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 153, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 154, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 155, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 156, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 157, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 158, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 159, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 160, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 161, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 162, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 163, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 164, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 165, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 166, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 167, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 168, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 169, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 170, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 171, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 172, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 173, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 174, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 175, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 176, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 177, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 178, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 179, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 180, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 181, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 182, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 183, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 184, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 185, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 186, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 187, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 188, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 189, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 190, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 191, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 192, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 193, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 194, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 195, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 196, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 197, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 198, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 199, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 200, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 201, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 202, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 203, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 204, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 205, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 206, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 207, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 208, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 209, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 210, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 211, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 212, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 213, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 214, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 215, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 216, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 217, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 218, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 219, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 220, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 221, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 222, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 223, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 224, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 225, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 226, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 227, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 228, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 229, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 230, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 231, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 232, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 233, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 234, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 235, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 236, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 237, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 238, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 239, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 240, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 241, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 242, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 243, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 244, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 245, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 246, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 247, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 248, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 249, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 250, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 251, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 252, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 253, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 254, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 255, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 256, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 257, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 258, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 259, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 260, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 261, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 262, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 263, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 264, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 265, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 266, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 267, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 268, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 269, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 270, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 271, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 272, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 273, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 274, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 275, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 276, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 277, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 278, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 279, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 280, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 281, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 282, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 283, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 284, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 285, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 286, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 287, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 288, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 289, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 290, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 291, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 292, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 293, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 294, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 295, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 296, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 297, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 298, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 299, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 300, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 301, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 302, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 303, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 304, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 305, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 306, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 307, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 308, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 309, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 310, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 311, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 312, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 313, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 314, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 315, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 316, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 317, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 318, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 319, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 320, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 321, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 322, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 323, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 324, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 325, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 326, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 327, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 328, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 329, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 330, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 331, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 332, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 333, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 334, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 335, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 336, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 337, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 338, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 339, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 340, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 341, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 342, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 343, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 344, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 345, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 346, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 347, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 348, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 349, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 350, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 351, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 352, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 353, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 354, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 355, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 356, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 357, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 358, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 359, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 360, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 361, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 362, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 363, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 364, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 365, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 366, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 367, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 368, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 369, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 370, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 371, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 372, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 373, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 374, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 375, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 376, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 377, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 378, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 379, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 380, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 381, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 382, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 383, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 384, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 385, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 386, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 387, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 388, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 389, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 390, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 391, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 392, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 393, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 394, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 395, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 396, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 397, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 398, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 399, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 400, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 401, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 402, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 403, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 404, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 405, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 406, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 407, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 408, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 409, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 410, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 411, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 412, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 413, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 414, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 415, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 416, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 417, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 418, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 419, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 420, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 421, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 422, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 423, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 424, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 425, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 426, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 427, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 428, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 429, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 430, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 431, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 432, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 433, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 434, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 435, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 436, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 437, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 438, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 439, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 440, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 441, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 442, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 443, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 444, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 445, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 446, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 447, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 448, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 449, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 450, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 451, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 452, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 453, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 454, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 455, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 456, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 457, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 458, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 459, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 460, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 461, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 462, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 463, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 464, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 465, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 466, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 467, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 468, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 469, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 470, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 471, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 472, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 473, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 474, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 475, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 476, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 477, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 478, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 479, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 480, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 481, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 482, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 483, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 484, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 485, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 486, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 487, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 488, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 489, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 490, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 491, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 492, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 493, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 494, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 495, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 496, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 497, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 498, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 499, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 500, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 501, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 502, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 503, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 504, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 505, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 506, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 507, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 508, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 509, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 510, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 511, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 512, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 513, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 514, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 515, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 516, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 517, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 518, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 519, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 520, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 521, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 522, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 523, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 524, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 525, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 526, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 527, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 528, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 529, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 530, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 531, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 532, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 533, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 534, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 535, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 536, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 537, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 538, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 539, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 540, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 541, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 542, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 543, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 544, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 545, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 546, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 547, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 548, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 549, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 550, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 551, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 552, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 553, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 554, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 555, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 556, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 557, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 558, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 559, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 560, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 561, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 562, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 563, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 564, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 565, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 566, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 567, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 568, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 569, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 570, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 571, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 572, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 573, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 574, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 575, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 576, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 577, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 578, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 579, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 580, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 581, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 582, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 583, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 584, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 585, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 586, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 587, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 588, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 589, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 590, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 591, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 592, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 593, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 594, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 595, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 596, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 597, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 598, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 599, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 600, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 601, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 602, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 603, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 604, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 605, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 606, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 607, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 608, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 609, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 610, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 611, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 612, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 613, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 614, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 615, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 616, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 617, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 618, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 619, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 620, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 621, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 622, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 623, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 624, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 625, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 626, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 627, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 628, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 629, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 630, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 631, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 632, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 633, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 634, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 635, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 636, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 637, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 638, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 639, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 640, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 641, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 642, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 643, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 644, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 645, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 646, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 647, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 648, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 649, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 650, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 651, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 652, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 653, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 654, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 655, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 656, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 657, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 658, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 659, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 660, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 661, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 662, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 663, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 664, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 665, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 666, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 667, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 668, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 669, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 670, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 671, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 672, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 673, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 674, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 675, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 676, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 677, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 678, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 679, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 680, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 681, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 682, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 683, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 684, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 685, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 686, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 687, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 688, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 689, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 690, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 691, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 692, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 693, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 694, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 695, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 696, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 697, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 698, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 699, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 700, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 701, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 702, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 703, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 704, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 705, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 706, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 707, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 708, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 709, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 710, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 711, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 712, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 713, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 714, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 715, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 716, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 717, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 718, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 719, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 720, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 721, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 722, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 723, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 724, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 725, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 726, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 727, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 728, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 729, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 730, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 731, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 732, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 733, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 734, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 735, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 736, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 737, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 738, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 739, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 740, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 741, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 742, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 743, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 744, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 745, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 746, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 747, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 748, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 749, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 750, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 751, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 752, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 753, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 754, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 755, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 756, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 757, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 758, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 759, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 760, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 761, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 762, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 763, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 764, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 765, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 766, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 767, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 768, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 769, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 770, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 771, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 772, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 773, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 774, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 775, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 776, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 777, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 778, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 779, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 780, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 781, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 782, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 783, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 784, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 785, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 786, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 787, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 788, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 789, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 790, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 791, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 792, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 793, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 794, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 795, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 796, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 797, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 798, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 799, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 800, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 801, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 802, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 803, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 804, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 805, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 806, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 807, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 808, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 809, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 810, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 811, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 812, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 813, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 814, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 815, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 816, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 817, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 818, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 819, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 820, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 821, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 822, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 823, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 824, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 825, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 826, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 827, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 828, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 829, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 830, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 831, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 832, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 833, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 834, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 835, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 836, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 837, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 838, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 839, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 840, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 841, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 842, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 843, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 844, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 845, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 846, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 847, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 848, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 849, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 850, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 851, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 852, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 853, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 854, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 855, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 856, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 857, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 858, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 859, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 860, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 861, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 862, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 863, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 864, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 865, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 866, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 867, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 868, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 869, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 870, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 871, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 872, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 873, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 874, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 875, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 876, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 877, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 878, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 879, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 880, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 881, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 882, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 883, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 884, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 885, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 886, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 887, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 888, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 889, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 890, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 891, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 892, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 893, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 894, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 895, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 896, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 897, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 898, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 899, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 900, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 901, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 902, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 903, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 904, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 905, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 906, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 907, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 908, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 909, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 910, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 911, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 912, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 913, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 914, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 915, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 916, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 917, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 918, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 919, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 920, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 921, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 922, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 923, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 924, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 925, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 926, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 927, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 928, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 929, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 930, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 931, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 932, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 933, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 934, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 935, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 936, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 937, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 938, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 939, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 940, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 941, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 942, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 943, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 944, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 945, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 946, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 947, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 948, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 949, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 950, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 951, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 952, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 953, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 954, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 955, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 956, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 957, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 958, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 959, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 960, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 961, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 962, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 963, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 964, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 965, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 966, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 967, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 968, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 969, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 970, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 971, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 972, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 973, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 974, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 975, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 976, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 977, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 978, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 979, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 980, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 981, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 982, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 983, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 984, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 985, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 986, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 987, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 988, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 989, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 990, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 991, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 992, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 993, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 994, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 995, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 996, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 997, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 998, loss 0.0\n",
      "tensor(0., grad_fn=<MseLossBackward0>)\n",
      "epoch 999, loss 0.0\n"
     ]
    }
   ],
   "source": [
    "from helper_libs.scn_side.machine_learning.ModelUtility import ModelUtility\n",
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48.]\n",
      " [ 7.]\n",
      " [62.]\n",
      " [48.]\n",
      " [51.]\n",
      " [60.]\n",
      " [68.]\n",
      " [24.]\n",
      " [52.]\n",
      " [53.]\n",
      " [50.]\n",
      " [63.]\n",
      " [68.]\n",
      " [68.]\n",
      " [68.]\n",
      " [40.]\n",
      " [47.]\n",
      " [47.]\n",
      " [60.]\n",
      " [62.]\n",
      " [61.]\n",
      " [60.]\n",
      " [48.]\n",
      " [21.]\n",
      " [42.]\n",
      " [61.]\n",
      " [75.]\n",
      " [69.]\n",
      " [75.]\n",
      " [68.]\n",
      " [55.]\n",
      " [73.]\n",
      " [61.]\n",
      " [60.]\n",
      " [70.]\n",
      " [65.]\n",
      " [76.]\n",
      " [72.]\n",
      " [69.]\n",
      " [82.]\n",
      " [46.]\n",
      " [45.]\n",
      " [47.]\n",
      " [35.]\n",
      " [54.]\n",
      " [54.]\n",
      " [48.]\n",
      " [11.]\n",
      " [73.]\n",
      " [60.]\n",
      " [53.]\n",
      " [54.]\n",
      " [53.]\n",
      " [62.]\n",
      " [63.]\n",
      " [35.]\n",
      " [76.]\n",
      " [76.]\n",
      " [73.]\n",
      " [59.]\n",
      " [67.]\n",
      " [67.]\n",
      " [15.]\n",
      " [46.]\n",
      " [55.]\n",
      " [44.]\n",
      " [67.]\n",
      " [45.]\n",
      " [65.]\n",
      " [26.]\n",
      " [61.]\n",
      " [46.]\n",
      " [64.]\n",
      " [53.]\n",
      " [56.]\n",
      " [ 5.]\n",
      " [48.]\n",
      " [67.]\n",
      " [70.]\n",
      " [56.]\n",
      " [74.]\n",
      " [45.]\n",
      " [38.]\n",
      " [48.]\n",
      " [59.]\n",
      " [70.]\n",
      " [56.]\n",
      " [70.]\n",
      " [58.]\n",
      " [50.]\n",
      " [63.]\n",
      " [56.]\n",
      " [71.]\n",
      " [73.]\n",
      " [65.]\n",
      " [62.]\n",
      " [60.]\n",
      " [65.]\n",
      " [50.]\n",
      " [56.]\n",
      " [34.]\n",
      " [71.]\n",
      " [17.]\n",
      " [76.]\n",
      " [55.]\n",
      " [65.]\n",
      " [50.]\n",
      " [55.]\n",
      " [45.]\n",
      " [54.]\n",
      " [63.]\n",
      " [65.]\n",
      " [52.]\n",
      " [61.]\n",
      " [12.]\n",
      " [47.]\n",
      " [49.]\n",
      " [55.]\n",
      " [55.]\n",
      " [60.]\n",
      " [72.]\n",
      " [54.]\n",
      " [34.]\n",
      " [43.]\n",
      " [65.]\n",
      " [72.]\n",
      " [70.]\n",
      " [71.]\n",
      " [52.]\n",
      " [75.]\n",
      " [50.]\n",
      " [ 5.]\n",
      " [50.]\n",
      " [70.]\n",
      " [47.]\n",
      " [48.]\n",
      " [46.]\n",
      " [45.]\n",
      " [73.]\n",
      " [41.]\n",
      " [69.]\n",
      " [67.]\n",
      " [72.]\n",
      " [41.]\n",
      " [60.]\n",
      " [57.]\n",
      " [53.]\n",
      " [60.]\n",
      " [69.]\n",
      " [65.]\n",
      " [ 8.]\n",
      " [76.]\n",
      " [39.]\n",
      " [55.]\n",
      " [56.]\n",
      " [50.]\n",
      " [66.]\n",
      " [62.]\n",
      " [71.]\n",
      " [59.]\n",
      " [81.]\n",
      " [62.]\n",
      " [59.]\n",
      " [46.]\n",
      " [14.]\n",
      " [60.]\n",
      " [27.]\n",
      " [34.]\n",
      " [65.]\n",
      " [55.]\n",
      " [66.]\n",
      " [83.]\n",
      " [62.]\n",
      " [17.]\n",
      " [54.]\n",
      " [60.]\n",
      " [21.]\n",
      " [65.]\n",
      " [42.]\n",
      " [72.]\n",
      " [73.]\n",
      " [45.]\n",
      " [61.]\n",
      " [30.]\n",
      " [54.]\n",
      " [ 4.]\n",
      " [ 8.]\n",
      " [ 3.]\n",
      " [ 8.]\n",
      " [64.]\n",
      " [ 6.]\n",
      " [52.]\n",
      " [46.]\n",
      " [32.]\n",
      " [80.]\n",
      " [70.]\n",
      " [49.]\n",
      " [57.]\n",
      " [59.]\n",
      " [65.]\n",
      " [90.]\n",
      " [64.]\n",
      " [78.]\n",
      " [55.]\n",
      " [65.]\n",
      " [61.]\n",
      " [60.]\n",
      " [50.]\n",
      " [67.]\n",
      " [19.]\n",
      " [59.]\n",
      " [54.]\n",
      " [40.]\n",
      " [55.]\n",
      " [68.]\n",
      " [ 2.]\n",
      " [64.]\n",
      " [63.]\n",
      " [33.]\n",
      " [68.]\n",
      " [36.]\n",
      " [66.]\n",
      " [74.]\n",
      " [71.]\n",
      " [34.]\n",
      " [60.]\n",
      " [64.]\n",
      " [57.]\n",
      " [60.]\n",
      " [59.]\n",
      " [65.]\n",
      " [60.]\n",
      " [50.]\n",
      " [51.]\n",
      " [37.]\n",
      " [45.]\n",
      " [65.]\n",
      " [80.]\n",
      " [72.]\n",
      " [34.]\n",
      " [65.]\n",
      " [57.]\n",
      " [69.]\n",
      " [62.]\n",
      " [64.]\n",
      " [48.]\n",
      " [48.]\n",
      " [54.]\n",
      " [59.]\n",
      " [56.]\n",
      " [40.]\n",
      " [23.]\n",
      " [45.]\n",
      " [57.]\n",
      " [51.]\n",
      " [34.]\n",
      " [60.]\n",
      " [38.]\n",
      " [42.]\n",
      " [35.]\n",
      " [30.]\n",
      " [49.]\n",
      " [55.]\n",
      " [45.]\n",
      " [42.]\n",
      " [50.]\n",
      " [55.]\n",
      " [48.]\n",
      " [49.]\n",
      " [25.]\n",
      " [23.]\n",
      " [30.]\n",
      " [56.]\n",
      " [47.]\n",
      " [19.]\n",
      " [52.]\n",
      " [20.]\n",
      " [46.]\n",
      " [48.]\n",
      " [24.]\n",
      " [47.]\n",
      " [55.]\n",
      " [20.]\n",
      " [60.]\n",
      " [33.]\n",
      " [66.]\n",
      " [71.]\n",
      " [39.]\n",
      " [56.]\n",
      " [42.]\n",
      " [54.]\n",
      " [47.]\n",
      " [30.]\n",
      " [50.]\n",
      " [75.]\n",
      " [44.]\n",
      " [41.]\n",
      " [53.]\n",
      " [34.]\n",
      " [73.]\n",
      " [45.]\n",
      " [44.]\n",
      " [29.]\n",
      " [55.]\n",
      " [33.]\n",
      " [41.]\n",
      " [52.]\n",
      " [47.]\n",
      " [43.]\n",
      " [51.]\n",
      " [46.]\n",
      " [56.]\n",
      " [80.]\n",
      " [55.]\n",
      " [39.]\n",
      " [44.]\n",
      " [35.]\n",
      " [58.]\n",
      " [61.]\n",
      " [30.]\n",
      " [57.]\n",
      " [65.]\n",
      " [70.]\n",
      " [43.]\n",
      " [40.]\n",
      " [58.]\n",
      " [47.]\n",
      " [30.]\n",
      " [28.]\n",
      " [33.]\n",
      " [43.]\n",
      " [59.]\n",
      " [34.]\n",
      " [23.]\n",
      " [24.]\n",
      " [60.]\n",
      " [25.]\n",
      " [44.]\n",
      " [62.]\n",
      " [25.]\n",
      " [32.]\n",
      " [63.]\n",
      " [44.]\n",
      " [37.]\n",
      " [64.]\n",
      " [22.]\n",
      " [33.]\n",
      " [43.]\n",
      " [38.]\n",
      " [35.]\n",
      " [65.]\n",
      " [29.]\n",
      " [37.]\n",
      " [39.]\n",
      " [32.]\n",
      " [23.]\n",
      " [34.]\n",
      " [66.]\n",
      " [47.]\n",
      " [74.]\n",
      " [35.]\n",
      " [29.]\n",
      " [33.]\n",
      " [67.]\n",
      " [73.]\n",
      " [24.]\n",
      " [60.]\n",
      " [68.]\n",
      " [30.]\n",
      " [75.]\n",
      " [69.]\n",
      " [28.]\n",
      " [72.]\n",
      " [61.]\n",
      " [79.]\n",
      " [70.]\n",
      " [58.]\n",
      " [64.]\n",
      " [71.]\n",
      " [62.]\n",
      " [59.]\n",
      " [71.]\n",
      " [48.]\n",
      " [80.]\n",
      " [57.]\n",
      " [63.]\n",
      " [46.]\n",
      " [15.]\n",
      " [51.]\n",
      " [41.]\n",
      " [52.]\n",
      " [36.]\n",
      " [57.]\n",
      " [43.]\n",
      " [50.]\n",
      " [55.]\n",
      " [42.]\n",
      " [12.]\n",
      " [17.]\n",
      " [58.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predicted = model(inputs).data.numpy()\n",
    "print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(inputs, labels, 'go', label='True data', alpha=0.2)\n",
    "plt.plot(inputs, predicted, '--', label='Predictions', alpha=0.7)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(predicted, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38_sail",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b6edbe5638b3feacd7106d40a106e2c3e12ceb182912a9b721169069f1c54c2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
