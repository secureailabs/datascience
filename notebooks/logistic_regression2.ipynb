{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions\n",
    "\n",
    "- Safe objects will persist in SCN memory until they are either moved, deleted manually or the SCN is powered off. \n",
    "- A LinearRegressionClient object will be on each SCN\n",
    "- A LinearRegressionFederated object will be with the orchestrator\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (340585904.py, line 51)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def run(in_layer, out_layer, x_data, y_data learn_rate=0.1, criterion=None, optimizer=None, epochs=10):\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class LinearRegressionClient(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionClient, self).__init__()\n",
    "        # self.linear = torch.nn.Linear(in_layer, out_layer, bias=True)\n",
    "        # self.criterion = criterion\n",
    "        # optimizer = torch.optim.SGD(self.linear.parameters(), lr=learn_rate)\n",
    "        # self.optimizer = optimizer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "    def train_model(self, epochs: int, x_data, y_data):\n",
    "        for epoch in range(epochs):\n",
    "            model = self.linear\n",
    "            model.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            y_pred = model(x_data)\n",
    "            # Compute Loss\n",
    "            loss = self.criterion(y_pred, y_data)\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        print(\"Loss: \"+ str(loss.data.view(-1)))\n",
    "\n",
    "    \n",
    "    def set_parameters_as_tensor(self, weights: torch.Tensor):\n",
    "        if not isinstance(weights, torch.Tensor):\n",
    "            print(\"Converting weights to tensor type\")\n",
    "            weights = torch.tensor(weights)\n",
    "        current_index = 0 \n",
    "        for parameter in self.parameters():\n",
    "            numel = parameter.data.numel()\n",
    "            size = parameter.data.size()\n",
    "            parameter.data.copy_(\n",
    "                            weights[current_index:current_index +\n",
    "                                                numel].view(size))\n",
    "            current_index+=1\n",
    "\n",
    "    def get_parameters_as_tensor(self):\n",
    "        params = [param.data.view(-1) for param in self.parameters()]\n",
    "        params = torch.cat(params)\n",
    "        params = params.cpu()\n",
    "        return params\n",
    "\n",
    "    def run(in_layer, out_layer, x_data, y_data learn_rate=0.1, criterion=None, optimizer=None, epochs=10):\n",
    "        \n",
    "        super(LinearRegressionClient, self).__init__()\n",
    "        linear = torch.nn.Linear(in_layer, out_layer, bias=True)\n",
    "        criterion = torch.nn.MSELoss(size_average=False)\n",
    "        optimizer = torch.optim.SGD(self.linear.parameters(), lr=learn_rate)\n",
    "\n",
    "        train_model(epochs, x_data, y_data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionFederated:\n",
    "    def __init__(self, models: LinearRegressionClient, data_federation):\n",
    "        self.models = models\n",
    "        self.data_federation = data_federation\n",
    "    \n",
    "    def get_average_model(self):\n",
    "\n",
    "        #Pull parameters for each model locally\n",
    "        model_parameters = []\n",
    "        for model in self.models:\n",
    "            model_parameters.append(model.get_parameters_as_tensor())\n",
    "        \n",
    "        #TODO: Push list of model parameters to some SCN\n",
    "        for param in model_parameters:\n",
    "            # param.send(models[random])\n",
    "            break\n",
    "            \n",
    "        #Calculate the Mean Remotely\n",
    "        #TODO: DO this using existing safe object\n",
    "        model_sum = 0.\n",
    "        for param in model_parameters:\n",
    "            model_sum += param\n",
    "        model_avg = model_sum/len(self.models)\n",
    "        #TODO: Pull result to orchestrator\n",
    "\n",
    "        return model_avg\n",
    "    \n",
    "    def train_cycle(self, epochs: int):\n",
    "        #train individual models on data\n",
    "        for i in range(len(self.models)):\n",
    "            models[i].train_model(epochs, data_federation[i][0], data_federation[i][1])\n",
    "        \n",
    "        #average the models\n",
    "        avg_model = self.get_average_model()\n",
    "        for i in range(len(self.models)):\n",
    "            models[i].set_parameters_as_tensor(avg_model)\n",
    "\n",
    "        #TODO:Pull Result locally           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Starts with respective owners A and B\n",
    "x_dataA = Variable(torch.Tensor([[10.0], [9.0], [3.0], [2.0]]))\n",
    "y_dataA = Variable(torch.Tensor([[90.0], [80.0], [50.0], [30.0]]))\n",
    "x_dataB = Variable(torch.Tensor([[7.0], [8.0], [3.0], [1.0]]))\n",
    "y_dataB = Variable(torch.Tensor([[60.0], [70.0], [40.0], [20.0]]))\n",
    "data_federation = [[x_dataA, y_dataA], [x_dataB, y_dataB]]\n",
    "        \n",
    "modelA = LinearRegressionClient(1,1)\n",
    "modelB = LinearRegressionClient(1,1)\n",
    "models = [modelA, modelB]\n",
    "\n",
    "federated_model = LinearRegressionFederated(models, data_federation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: tensor([31640224.])\n",
      "Loss: tensor([6174763.])\n",
      "Loss: tensor([3.1239e+13])\n",
      "Loss: tensor([7.9251e+12])\n",
      "Loss: tensor([3.3114e+19])\n",
      "Loss: tensor([8.4019e+18])\n",
      "Loss: tensor([3.5102e+25])\n",
      "Loss: tensor([8.9065e+24])\n",
      "Loss: tensor([3.7210e+31])\n",
      "Loss: tensor([9.4414e+30])\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    # print(federated_model.models[0].get_parameters_as_tensor())\n",
    "    # print(federated_model.models[1].get_parameters_as_tensor())\n",
    "    federated_model.train_cycle(2)\n",
    "    # print(federated_model.models[0].get_parameters_as_tensor())\n",
    "    # print(federated_model.models[1].get_parameters_as_tensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a551a9fda4b0fd0844678eafd3b71ce0ebfefa198dcee60abe1926ee3f4a81d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv38_sail': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
