{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# create dummy data for training\n",
    "x_values = [i for i in range(11)]\n",
    "x_train = np.array(x_values, dtype=np.float32)\n",
    "x_train = x_train.reshape(-1, 1)\n",
    "\n",
    "y_values = [2*i + 1 for i in x_values]\n",
    "y_train = np.array(y_values, dtype=np.float32)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "x_train = torch.from_numpy(x_train)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "data_federation = [[x_train, y_train], [x_train, y_train]]\n",
    "\n",
    "in_layer = len(data_federation[0][0][0])\n",
    "out_layer = len(data_federation[0][1][0])\n",
    "optimizer = \"SGD\"\n",
    "criterion = \"MSELoss\"\n",
    "starting_model = torch.rand(in_layer, out_layer)\n",
    "epochs = 100\n",
    "learn_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sail_safe_functions.machine_learning.linear_regression.LinearRegression import LinearRegression\n",
    "\n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = linearRegression(in_layer, out_layer)\n",
    "\n",
    "criterion = torch.nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(276.0891, grad_fn=<MseLossBackward0>)\n",
      "epoch 0, loss 276.08905029296875\n",
      "tensor(22.9512, grad_fn=<MseLossBackward0>)\n",
      "epoch 1, loss 22.951162338256836\n",
      "tensor(2.2987, grad_fn=<MseLossBackward0>)\n",
      "epoch 2, loss 2.298687696456909\n",
      "tensor(0.6094, grad_fn=<MseLossBackward0>)\n",
      "epoch 3, loss 0.609365701675415\n",
      "tensor(0.4669, grad_fn=<MseLossBackward0>)\n",
      "epoch 4, loss 0.4668623208999634\n",
      "tensor(0.4506, grad_fn=<MseLossBackward0>)\n",
      "epoch 5, loss 0.4505802094936371\n",
      "tensor(0.4446, grad_fn=<MseLossBackward0>)\n",
      "epoch 6, loss 0.44464585185050964\n",
      "tensor(0.4396, grad_fn=<MseLossBackward0>)\n",
      "epoch 7, loss 0.43960678577423096\n",
      "tensor(0.4347, grad_fn=<MseLossBackward0>)\n",
      "epoch 8, loss 0.4346919357776642\n",
      "tensor(0.4298, grad_fn=<MseLossBackward0>)\n",
      "epoch 9, loss 0.42983731627464294\n",
      "tensor(0.4250, grad_fn=<MseLossBackward0>)\n",
      "epoch 10, loss 0.4250372052192688\n",
      "tensor(0.4203, grad_fn=<MseLossBackward0>)\n",
      "epoch 11, loss 0.42029091715812683\n",
      "tensor(0.4156, grad_fn=<MseLossBackward0>)\n",
      "epoch 12, loss 0.4155976474285126\n",
      "tensor(0.4110, grad_fn=<MseLossBackward0>)\n",
      "epoch 13, loss 0.41095656156539917\n",
      "tensor(0.4064, grad_fn=<MseLossBackward0>)\n",
      "epoch 14, loss 0.40636780858039856\n",
      "tensor(0.4018, grad_fn=<MseLossBackward0>)\n",
      "epoch 15, loss 0.4018296003341675\n",
      "tensor(0.3973, grad_fn=<MseLossBackward0>)\n",
      "epoch 16, loss 0.3973425030708313\n",
      "tensor(0.3929, grad_fn=<MseLossBackward0>)\n",
      "epoch 17, loss 0.39290550351142883\n",
      "tensor(0.3885, grad_fn=<MseLossBackward0>)\n",
      "epoch 18, loss 0.38851815462112427\n",
      "tensor(0.3842, grad_fn=<MseLossBackward0>)\n",
      "epoch 19, loss 0.38417959213256836\n",
      "tensor(0.3799, grad_fn=<MseLossBackward0>)\n",
      "epoch 20, loss 0.37988966703414917\n",
      "tensor(0.3756, grad_fn=<MseLossBackward0>)\n",
      "epoch 21, loss 0.37564709782600403\n",
      "tensor(0.3715, grad_fn=<MseLossBackward0>)\n",
      "epoch 22, loss 0.37145254015922546\n",
      "tensor(0.3673, grad_fn=<MseLossBackward0>)\n",
      "epoch 23, loss 0.36730462312698364\n",
      "tensor(0.3632, grad_fn=<MseLossBackward0>)\n",
      "epoch 24, loss 0.36320286989212036\n",
      "tensor(0.3591, grad_fn=<MseLossBackward0>)\n",
      "epoch 25, loss 0.3591468930244446\n",
      "tensor(0.3551, grad_fn=<MseLossBackward0>)\n",
      "epoch 26, loss 0.3551364541053772\n",
      "tensor(0.3512, grad_fn=<MseLossBackward0>)\n",
      "epoch 27, loss 0.35117074847221375\n",
      "tensor(0.3472, grad_fn=<MseLossBackward0>)\n",
      "epoch 28, loss 0.34724941849708557\n",
      "tensor(0.3434, grad_fn=<MseLossBackward0>)\n",
      "epoch 29, loss 0.34337174892425537\n",
      "tensor(0.3395, grad_fn=<MseLossBackward0>)\n",
      "epoch 30, loss 0.33953729271888733\n",
      "tensor(0.3357, grad_fn=<MseLossBackward0>)\n",
      "epoch 31, loss 0.3357456922531128\n",
      "tensor(0.3320, grad_fn=<MseLossBackward0>)\n",
      "epoch 32, loss 0.3319966197013855\n",
      "tensor(0.3283, grad_fn=<MseLossBackward0>)\n",
      "epoch 33, loss 0.3282892405986786\n",
      "tensor(0.3246, grad_fn=<MseLossBackward0>)\n",
      "epoch 34, loss 0.32462310791015625\n",
      "tensor(0.3210, grad_fn=<MseLossBackward0>)\n",
      "epoch 35, loss 0.3209981620311737\n",
      "tensor(0.3174, grad_fn=<MseLossBackward0>)\n",
      "epoch 36, loss 0.31741341948509216\n",
      "tensor(0.3139, grad_fn=<MseLossBackward0>)\n",
      "epoch 37, loss 0.3138689696788788\n",
      "tensor(0.3104, grad_fn=<MseLossBackward0>)\n",
      "epoch 38, loss 0.3103642761707306\n",
      "tensor(0.3069, grad_fn=<MseLossBackward0>)\n",
      "epoch 39, loss 0.3068985641002655\n",
      "tensor(0.3035, grad_fn=<MseLossBackward0>)\n",
      "epoch 40, loss 0.3034713566303253\n",
      "tensor(0.3001, grad_fn=<MseLossBackward0>)\n",
      "epoch 41, loss 0.3000822961330414\n",
      "tensor(0.2967, grad_fn=<MseLossBackward0>)\n",
      "epoch 42, loss 0.29673174023628235\n",
      "tensor(0.2934, grad_fn=<MseLossBackward0>)\n",
      "epoch 43, loss 0.29341790080070496\n",
      "tensor(0.2901, grad_fn=<MseLossBackward0>)\n",
      "epoch 44, loss 0.2901417016983032\n",
      "tensor(0.2869, grad_fn=<MseLossBackward0>)\n",
      "epoch 45, loss 0.2869017422199249\n",
      "tensor(0.2837, grad_fn=<MseLossBackward0>)\n",
      "epoch 46, loss 0.28369760513305664\n",
      "tensor(0.2805, grad_fn=<MseLossBackward0>)\n",
      "epoch 47, loss 0.28052976727485657\n",
      "tensor(0.2774, grad_fn=<MseLossBackward0>)\n",
      "epoch 48, loss 0.2773967981338501\n",
      "tensor(0.2743, grad_fn=<MseLossBackward0>)\n",
      "epoch 49, loss 0.2742995023727417\n",
      "tensor(0.2712, grad_fn=<MseLossBackward0>)\n",
      "epoch 50, loss 0.27123650908470154\n",
      "tensor(0.2682, grad_fn=<MseLossBackward0>)\n",
      "epoch 51, loss 0.2682075798511505\n",
      "tensor(0.2652, grad_fn=<MseLossBackward0>)\n",
      "epoch 52, loss 0.2652125656604767\n",
      "tensor(0.2623, grad_fn=<MseLossBackward0>)\n",
      "epoch 53, loss 0.2622511088848114\n",
      "tensor(0.2593, grad_fn=<MseLossBackward0>)\n",
      "epoch 54, loss 0.25932249426841736\n",
      "tensor(0.2564, grad_fn=<MseLossBackward0>)\n",
      "epoch 55, loss 0.25642645359039307\n",
      "tensor(0.2536, grad_fn=<MseLossBackward0>)\n",
      "epoch 56, loss 0.25356313586235046\n",
      "tensor(0.2507, grad_fn=<MseLossBackward0>)\n",
      "epoch 57, loss 0.250731498003006\n",
      "tensor(0.2479, grad_fn=<MseLossBackward0>)\n",
      "epoch 58, loss 0.24793173372745514\n",
      "tensor(0.2452, grad_fn=<MseLossBackward0>)\n",
      "epoch 59, loss 0.24516290426254272\n",
      "tensor(0.2424, grad_fn=<MseLossBackward0>)\n",
      "epoch 60, loss 0.24242518842220306\n",
      "tensor(0.2397, grad_fn=<MseLossBackward0>)\n",
      "epoch 61, loss 0.23971810936927795\n",
      "tensor(0.2370, grad_fn=<MseLossBackward0>)\n",
      "epoch 62, loss 0.2370414137840271\n",
      "tensor(0.2344, grad_fn=<MseLossBackward0>)\n",
      "epoch 63, loss 0.23439450562000275\n",
      "tensor(0.2318, grad_fn=<MseLossBackward0>)\n",
      "epoch 64, loss 0.2317768931388855\n",
      "tensor(0.2292, grad_fn=<MseLossBackward0>)\n",
      "epoch 65, loss 0.22918877005577087\n",
      "tensor(0.2266, grad_fn=<MseLossBackward0>)\n",
      "epoch 66, loss 0.22662925720214844\n",
      "tensor(0.2241, grad_fn=<MseLossBackward0>)\n",
      "epoch 67, loss 0.22409877181053162\n",
      "tensor(0.2216, grad_fn=<MseLossBackward0>)\n",
      "epoch 68, loss 0.22159633040428162\n",
      "tensor(0.2191, grad_fn=<MseLossBackward0>)\n",
      "epoch 69, loss 0.21912160515785217\n",
      "tensor(0.2167, grad_fn=<MseLossBackward0>)\n",
      "epoch 70, loss 0.21667465567588806\n",
      "tensor(0.2143, grad_fn=<MseLossBackward0>)\n",
      "epoch 71, loss 0.21425539255142212\n",
      "tensor(0.2119, grad_fn=<MseLossBackward0>)\n",
      "epoch 72, loss 0.21186260879039764\n",
      "tensor(0.2095, grad_fn=<MseLossBackward0>)\n",
      "epoch 73, loss 0.20949687063694\n",
      "tensor(0.2072, grad_fn=<MseLossBackward0>)\n",
      "epoch 74, loss 0.20715731382369995\n",
      "tensor(0.2048, grad_fn=<MseLossBackward0>)\n",
      "epoch 75, loss 0.20484410226345062\n",
      "tensor(0.2026, grad_fn=<MseLossBackward0>)\n",
      "epoch 76, loss 0.20255650579929352\n",
      "tensor(0.2003, grad_fn=<MseLossBackward0>)\n",
      "epoch 77, loss 0.20029467344284058\n",
      "tensor(0.1981, grad_fn=<MseLossBackward0>)\n",
      "epoch 78, loss 0.19805780053138733\n",
      "tensor(0.1958, grad_fn=<MseLossBackward0>)\n",
      "epoch 79, loss 0.19584621489048004\n",
      "tensor(0.1937, grad_fn=<MseLossBackward0>)\n",
      "epoch 80, loss 0.1936594843864441\n",
      "tensor(0.1915, grad_fn=<MseLossBackward0>)\n",
      "epoch 81, loss 0.19149674475193024\n",
      "tensor(0.1894, grad_fn=<MseLossBackward0>)\n",
      "epoch 82, loss 0.18935833871364594\n",
      "tensor(0.1872, grad_fn=<MseLossBackward0>)\n",
      "epoch 83, loss 0.18724392354488373\n",
      "tensor(0.1852, grad_fn=<MseLossBackward0>)\n",
      "epoch 84, loss 0.1851530224084854\n",
      "tensor(0.1831, grad_fn=<MseLossBackward0>)\n",
      "epoch 85, loss 0.1830853521823883\n",
      "tensor(0.1810, grad_fn=<MseLossBackward0>)\n",
      "epoch 86, loss 0.18104082345962524\n",
      "tensor(0.1790, grad_fn=<MseLossBackward0>)\n",
      "epoch 87, loss 0.17901907861232758\n",
      "tensor(0.1770, grad_fn=<MseLossBackward0>)\n",
      "epoch 88, loss 0.1770201325416565\n",
      "tensor(0.1750, grad_fn=<MseLossBackward0>)\n",
      "epoch 89, loss 0.1750432848930359\n",
      "tensor(0.1731, grad_fn=<MseLossBackward0>)\n",
      "epoch 90, loss 0.17308872938156128\n",
      "tensor(0.1712, grad_fn=<MseLossBackward0>)\n",
      "epoch 91, loss 0.1711556762456894\n",
      "tensor(0.1692, grad_fn=<MseLossBackward0>)\n",
      "epoch 92, loss 0.16924449801445007\n",
      "tensor(0.1674, grad_fn=<MseLossBackward0>)\n",
      "epoch 93, loss 0.1673545241355896\n",
      "tensor(0.1655, grad_fn=<MseLossBackward0>)\n",
      "epoch 94, loss 0.16548575460910797\n",
      "tensor(0.1636, grad_fn=<MseLossBackward0>)\n",
      "epoch 95, loss 0.1636379212141037\n",
      "tensor(0.1618, grad_fn=<MseLossBackward0>)\n",
      "epoch 96, loss 0.16181060671806335\n",
      "tensor(0.1600, grad_fn=<MseLossBackward0>)\n",
      "epoch 97, loss 0.1600036770105362\n",
      "tensor(0.1582, grad_fn=<MseLossBackward0>)\n",
      "epoch 98, loss 0.1582169383764267\n",
      "tensor(0.1565, grad_fn=<MseLossBackward0>)\n",
      "epoch 99, loss 0.15645012259483337\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    inputs = Variable(x_train)\n",
    "    labels = Variable(y_train)\n",
    "\n",
    "    # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # get output from the model, given the inputs\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # get loss for the predicted output\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    # get gradients w.r.t to parameters\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.2642197]\n",
      " [ 2.3701787]\n",
      " [ 4.4761376]\n",
      " [ 6.5820966]\n",
      " [ 8.688055 ]\n",
      " [10.794014 ]\n",
      " [12.899973 ]\n",
      " [15.005932 ]\n",
      " [17.11189  ]\n",
      " [19.21785  ]\n",
      " [21.323809 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predicted = model(x_train).data.numpy()\n",
    "print(predicted)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(x_train, y_train, 'go', label='True data', alpha=0.5)\n",
    "plt.plot(x_train, predicted, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
